{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSnK+ZDaP8WWE5RtwbB7Nd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jothiovia-2004/project/blob/main/Automated_Research_Paper_Reviewer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmnV35kvULMI",
        "outputId": "d0407979-9ed3-4728-e2ac-14de79e37e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tools\n",
            "  Downloading tools-1.0.5-py3-none-any.whl.metadata (1.3 kB)\n",
            "Downloading tools-1.0.5-py3-none-any.whl (40 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tools\n",
            "Successfully installed tools-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey58umy_s2-r",
        "outputId": "9880b549-5307-47d8-a1a9-9804d042d6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # from PyMuPDF\n"
      ],
      "metadata": {
        "id": "ICsXby0es-Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiIFPtqiA03f",
        "outputId": "93f1d938-2be2-44aa-b4ee-fe5ba53bcc4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Automated Research Paper Reviewer (prototype)\n",
        "\n",
        "Usage (CLI):\n",
        "    !python paper_reviewer.py --input \"\"/content/Object_Distance_Estimation_from_a_Single_Moving_Camera_for_Advanced_Driver_Assistance_System.pdf\"\" --device cpu\n",
        "\n",
        "\n",
        "Optional (Streamlit UI):\n",
        "    streamlit run paper_reviewer.py\n",
        "\n",
        "What it does (prototype):\n",
        " - Extract text from PDF (via PyMuPDF)\n",
        " - Chunk & summarize sections (transformers summarization)\n",
        " - Generate structured review items via a text-generation model (Flan-T5)\n",
        " - Provide simple novelty & clarity heuristics + candidate review lines\n",
        "\n",
        "Notes:\n",
        " - This is a prototype. Replace models or improve heuristics for production.\n",
        " - Large models may require GPU. Use --device cuda when available.\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import re\n",
        "import os\n",
        "from typing import List, Tuple, Dict\n",
        "from dataclasses import dataclass\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "# PDF extraction\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "# NLP\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "\n",
        "# Streamlit optional\n",
        "try:\n",
        "    import streamlit as st\n",
        "    STREAMLIT_AVAILABLE = True\n",
        "except Exception:\n",
        "    STREAMLIT_AVAILABLE = False\n",
        "\n",
        "# -----------------------------\n",
        "# Utility: PDF -> text\n",
        "# -----------------------------\n",
        "def extract_text_from_pdf(path: str) -> str:\n",
        "    doc = fitz.open(path)\n",
        "    texts = []\n",
        "    for page in doc:\n",
        "        txt = page.get_text(\"text\")\n",
        "        if txt:\n",
        "            texts.append(txt)\n",
        "    return \"\\n\\n\".join(texts)\n",
        "\n",
        "# -----------------------------\n",
        "# Heuristic: split into sections by common headings\n",
        "# -----------------------------\n",
        "SECTION_HEADINGS = [\n",
        "    r'abstract', r'introduction', r'related work', r'background', r'methods?',\n",
        "    r'methodology', r'approach', r'experimental', r'experiments', r'results?', r'discussion',\n",
        "    r'conclusion', r'conclusions', r'future work', r'acknowledg', r'references', r'references and notes'\n",
        "]\n",
        "\n",
        "def split_into_sections(text: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Returns list of (heading, content). If headings not found, returns single 'full_text'.\n",
        "    \"\"\"\n",
        "    # Normalize newlines and unify heading lines\n",
        "    lines = [l.strip() for l in text.splitlines()]\n",
        "    joined = \"\\n\".join(lines)\n",
        "    # find heading positions\n",
        "    pattern = r'(^|\\n)\\s*(%s)\\s*(\\n|$)' % \"|\".join(SECTION_HEADINGS)\n",
        "    matches = list(re.finditer(pattern, joined, flags=re.IGNORECASE | re.MULTILINE))\n",
        "    if not matches:\n",
        "        return [(\"full_text\", joined)]\n",
        "    sections = []\n",
        "    for i, m in enumerate(matches):\n",
        "        start = m.end()\n",
        "        heading = m.group(2).strip().title()\n",
        "        end = matches[i+1].start() if i+1 < len(matches) else len(joined)\n",
        "        content = joined[start:end].strip()\n",
        "        sections.append((heading, content))\n",
        "    # Merge small sections into neighbor if too short\n",
        "    merged = []\n",
        "    for h, c in sections:\n",
        "        if len(c.split()) < 50 and merged:\n",
        "            prev_h, prev_c = merged[-1]\n",
        "            merged[-1] = (prev_h, prev_c + \"\\n\\n\" + c)\n",
        "        else:\n",
        "            merged.append((h, c))\n",
        "    return merged\n",
        "\n",
        "# -----------------------------\n",
        "# Chunking helper\n",
        "# -----------------------------\n",
        "def chunk_text_by_sentences(text: str, max_words: int = 500) -> List[str]:\n",
        "    sents = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    cur = []\n",
        "    cur_words = 0\n",
        "    for s in sents:\n",
        "        w = len(s.split())\n",
        "        if cur_words + w > max_words and cur:\n",
        "            chunks.append(\" \".join(cur))\n",
        "            cur = [s]\n",
        "            cur_words = w\n",
        "        else:\n",
        "            cur.append(s)\n",
        "            cur_words += w\n",
        "    if cur:\n",
        "        chunks.append(\" \".join(cur))\n",
        "    return chunks\n",
        "\n",
        "# -----------------------------\n",
        "# Reviewer class that holds models\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class PaperReviewer:\n",
        "    device: str = \"cpu\"\n",
        "    # models will be loaded in __post_init__\n",
        "    summarizer = None\n",
        "    qg_model = None   # generation model (Flan-T5)\n",
        "    embedder = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        # 1) Summarization pipeline\n",
        "        print(\"Loading summarization model (facebook/bart-large-cnn)...\")\n",
        "        self.summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0 if self.device != \"cpu\" and \"cuda\" in self.device else -1)\n",
        "        # 2) Generation model for review-text generation (Flan-T5 small/medium)\n",
        "        print(\"Loading text generation model (google/flan-t5-base)...\")\n",
        "        self.qg_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "        self.qg_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
        "        if self.device != \"cpu\" and \"cuda\" in self.device:\n",
        "            self.qg_model = self.qg_model.to(self.device)\n",
        "        # 3) Sentence-transformer embedder for simple heuristics\n",
        "        print(\"Loading sentence-transformers embedder (all-MiniLM-L6-v2)...\")\n",
        "        self.embedder = SentenceTransformer(\"all-MiniLM-L6-v2\", device=self.device if self.device != \"cpu\" else \"cpu\")\n",
        "\n",
        "    # -------------------------\n",
        "    # Summarize a (possibly long) text by chunking\n",
        "    # -------------------------\n",
        "    def summarize_long(self, text: str, max_chunk_words: int = 400) -> str:\n",
        "        chunks = chunk_text_by_sentences(text, max_words=max_chunk_words)\n",
        "        summaries = []\n",
        "        for ch in tqdm(chunks, desc=\"Summarizing chunks\"):\n",
        "            try:\n",
        "                out = self.summarizer(ch, max_length=150, min_length=40, do_sample=False)\n",
        "                summaries.append(out[0]['summary_text'])\n",
        "            except Exception as e:\n",
        "                # fallback: short extractive fallback\n",
        "                summaries.append(\" \".join(ch.split()[:120]))\n",
        "        # if many chunks, summarize summaries again\n",
        "        joined = \" \".join(summaries)\n",
        "        if len(summaries) > 2:\n",
        "            try:\n",
        "                out = self.summarizer(joined, max_length=160, min_length=60, do_sample=False)\n",
        "                return out[0]['summary_text']\n",
        "            except Exception:\n",
        "                return joined\n",
        "        return joined\n",
        "\n",
        "    # -------------------------\n",
        "    # Generate structured review items using prompt-based generation\n",
        "    # -------------------------\n",
        "    def generate_review_prompt(self, abstract: str, summary: str, section_summaries: Dict[str,str]) -> str:\n",
        "        \"\"\"\n",
        "        Create a prompt for Flan-T5 to generate review sections.\n",
        "        We'll instruct it to output structured JSON-like text with headings.\n",
        "        \"\"\"\n",
        "        prompt = [\n",
        "            \"You are an expert academic reviewer. Given the paper abstract and a concise summary of the paper, produce a structured review with headings: SUMMARY, STRENGTHS, WEAKNESSES, NOVELTY_ASSESSMENT, CLARITY, METHODOLOGY_ISSUES, SUGGESTIONS, RECOMMENDATION.\",\n",
        "            \"Be concise. Use bullet points under STRENGTHS and WEAKNESSES. Use a final RECOMMENDATION of Accept / Revise / Reject with a short rationale.\",\n",
        "            \"\",\n",
        "            \"ABSTRACT:\",\n",
        "            abstract.strip()[:3000],\n",
        "            \"\",\n",
        "            \"CONSOLIDATED_SUMMARY:\",\n",
        "            summary.strip()[:4000],\n",
        "            \"\",\n",
        "            \"SECTION_SUMMARIES:\"\n",
        "        ]\n",
        "        for k, v in section_summaries.items():\n",
        "            prompt.append(f\"{k.upper()}:\\n{v.strip()[:1200]}\\n\")\n",
        "        prompt.append(\"\\nOutput:\")\n",
        "        return \"\\n\".join(prompt)\n",
        "\n",
        "    def generate_structured_review(self, abstract: str, summary: str, section_summaries: Dict[str,str], max_out_len:int=512) -> str:\n",
        "        prompt = self.generate_review_prompt(abstract, summary, section_summaries)\n",
        "        inputs = self.qg_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(self.qg_model.device)\n",
        "        outs = self.qg_model.generate(**inputs, max_length=max_out_len, num_beams=4, early_stopping=True)\n",
        "        text = self.qg_tokenizer.decode(outs[0], skip_special_tokens=True)\n",
        "        return text\n",
        "\n",
        "    # -------------------------\n",
        "    # Heuristic novelty score using semantic similarity to \"related work\" (if available)\n",
        "    # If related-work section exists, compute self-similarity between abstract and related-work\n",
        "    # Lower similarity -> potentially more novel. This is a heuristic only.\n",
        "    # -------------------------\n",
        "    def novelty_heuristic(self, abstract: str, related_work_text: str) -> float:\n",
        "        if not related_work_text or len(related_work_text.split()) < 20:\n",
        "            return 0.5  # unknown/neutral\n",
        "        a_emb = self.embedder.encode(abstract, convert_to_tensor=True)\n",
        "        r_emb = self.embedder.encode(related_work_text, convert_to_tensor=True)\n",
        "        sim = util.cos_sim(a_emb, r_emb).item()\n",
        "        # Map similarity to novelty score: lower sim -> higher novelty\n",
        "        novelty = max(0.0, min(1.0, 1.0 - sim))  # crude\n",
        "        return novelty\n",
        "\n",
        "    # -------------------------\n",
        "    # Find unclear sentences: sentences with many hedges / long incomprehensible sentences\n",
        "    # -------------------------\n",
        "    def unclear_sentences(self, text: str, top_k:int=5) -> List[str]:\n",
        "        sents = sent_tokenize(text)\n",
        "        # Score: very long sentences and many adjectives / commas are suspect\n",
        "        scores = []\n",
        "        for s in sents:\n",
        "            words = s.split()\n",
        "            length = len(words)\n",
        "            commas = s.count(',')\n",
        "            # simple readability heuristic\n",
        "            score = length * 0.6 + commas * 0.4\n",
        "            scores.append((score, s))\n",
        "        scores.sort(reverse=True)\n",
        "        return [s for _, s in scores[:top_k]]\n",
        "\n",
        "# -----------------------------\n",
        "# Main pipeline\n",
        "# -----------------------------\n",
        "def review_paper(path: str, device: str = \"cpu\") -> Dict:\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(path)\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".pdf\"]:\n",
        "        print(\"Extracting text from PDF...\")\n",
        "        text = extract_text_from_pdf(path)\n",
        "    elif ext in [\".txt\", \".md\"]:\n",
        "        text = open(path, \"r\", encoding=\"utf-8\").read()\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type. Provide PDF or TXT.\")\n",
        "    # split sections\n",
        "    print(\"Splitting into sections...\")\n",
        "    sections = split_into_sections(text)\n",
        "    sections_dict = {h: c for h, c in sections}\n",
        "    # get abstract if exists else first 250-400 words\n",
        "    abstract = sections_dict.get(\"Abstract\", None)\n",
        "    if not abstract:\n",
        "        # fallback: first 400 words\n",
        "        abstract = \" \".join(text.split()[:400])\n",
        "\n",
        "    # Summarize full paper\n",
        "    reviewer = PaperReviewer(device=device)\n",
        "    print(\"Summarizing the full paper (may take a while)...\")\n",
        "    full_summary = reviewer.summarize_long(text, max_chunk_words=450)\n",
        "\n",
        "    # Summarize each section (short)\n",
        "    section_summaries = {}\n",
        "    for h, c in sections:\n",
        "        if len(c.split()) < 40:\n",
        "            section_summaries[h] = c.strip()\n",
        "            continue\n",
        "        section_summaries[h] = reviewer.summarize_long(c, max_chunk_words=250)\n",
        "\n",
        "    # Generate structured review text\n",
        "    print(\"Generating structured review text...\")\n",
        "    structured = reviewer.generate_structured_review(abstract, full_summary, section_summaries, max_out_len=512)\n",
        "\n",
        "    # Heuristic novelty\n",
        "    related = sections_dict.get(\"Related Work\", \"\") or sections_dict.get(\"Related work\", \"\")\n",
        "    novelty_score = reviewer.novelty_heuristic(abstract, related)\n",
        "\n",
        "    # Unclear sentence highlights\n",
        "    unclear = reviewer.unclear_sentences(text, top_k=6)\n",
        "\n",
        "    # Candidate \"copy/paste\" review lines: take first few weaknesses/strengths by simple extraction:\n",
        "    candidate_lines = []\n",
        "    for block in structured.split(\"\\n\"):\n",
        "        if len(block.strip()) > 10 and len(block.split()) < 60:\n",
        "            candidate_lines.append(block.strip())\n",
        "    candidate_lines = candidate_lines[:10]\n",
        "\n",
        "    result = {\n",
        "        \"structured_review_text\": structured,\n",
        "        \"summary\": full_summary,\n",
        "        \"section_summaries\": section_summaries,\n",
        "        \"novelty_score_0_1\": novelty_score,\n",
        "        \"unclear_sentences\": unclear,\n",
        "        \"candidate_review_lines\": candidate_lines\n",
        "    }\n",
        "    return result\n",
        "\n",
        "# -----------------------------\n",
        "# CLI or Streamlit UI\n",
        "# -----------------------------\n",
        "# Removed argparse and direct call for Colab environment\n",
        "if __name__ == \"__main__\":\n",
        "    # If Streamlit available and running under streamlit, create a small UI\n",
        "    if STREAMLIT_AVAILABLE and \"streamlit\" in os.environ.get(\"PYTEST_CURRENT_TEST\", \"\") or (STREAMLIT_AVAILABLE and os.getenv(\"STREAMLIT_RUN\", None)):\n",
        "        # Not recommended — this block is mostly for direct streamlit run\n",
        "        st.title(\"Automated Research Paper Reviewer (Prototype)\")\n",
        "        uploaded = st.file_uploader(\"Upload PDF or TXT\", type=[\"pdf\", \"txt\"])\n",
        "        device = st.selectbox(\"Device\", [\"cpu\", \"cuda\"])\n",
        "        if uploaded and st.button(\"Run Review\"):\n",
        "            with open(\"uploaded_paper.pdf\", \"wb\") as f:\n",
        "                f.write(uploaded.getbuffer())\n",
        "            st.info(\"Processing — models will load. This may take a minute.\")\n",
        "            out = review_paper(\"uploaded_paper.pdf\", device=device)\n",
        "            st.header(\"Summary\")\n",
        "            st.write(out[\"summary\"])\n",
        "            st.header(\"Structured Review\")\n",
        "            st.text(out[\"structured_review_text\"])\n",
        "            st.header(\"Novelty (heuristic)\")\n",
        "            st.write(out[\"novelty_score_0_1\"])\n",
        "            st.header(\"Unclear sentences\")\n",
        "            for s in out[\"unclear_sentences\"]:\n",
        "                st.write(s)\n",
        "            st.header(\"Candidate lines (copy/paste)\")\n",
        "            for l in out[\"candidate_review_lines\"]:\n",
        "                st.write(\"-\", l)\n",
        "    else:\n",
        "        # Example usage in Colab\n",
        "        dummy_paper_path = \"/content/Object_Distance_Estimation_from_a_Single_Moving_Camera_for_Advanced_Driver_Assistance_System.pdf\"  # Replace with the actual path to your paper\n",
        "        device_to_use = \"cpu\" # or \"cuda\" if you have a GPU\n",
        "        if os.path.exists(dummy_paper_path):\n",
        "            print(f\"Reviewing {dummy_paper_path}\")\n",
        "            out = review_paper(dummy_paper_path, device=device_to_use)\n",
        "            print(\"\\n=== SHORT SUMMARY ===\\n\")\n",
        "            print(out[\"summary\"])\n",
        "            print(\"\\n=== STRUCTURED REVIEW ===\\n\")\n",
        "            print(out[\"structured_review_text\"])\n",
        "            print(\"\\n=== NOVELTY HEURISTIC ===\\n\")\n",
        "            print(f\"Novelty score (0 low - 1 high): {out['novelty_score_0_1']:.3f}\")\n",
        "            print(\"\\n=== UNCLEAR SENTENCES (examples) ===\\n\")\n",
        "            for s in out['unclear_sentences']:\n",
        "                print(\"- \", s[:300].replace(\"\\n\", \" \"))\n",
        "            print(\"\\n=== CANDIDATE LINES (copy/paste) ===\\n\")\n",
        "            for l in out['candidate_review_lines']:\n",
        "                print(\"-\", l)\n",
        "        else:\n",
        "            print(f\"Error: The file {dummy_paper_path} was not found. Please replace with the actual path to your paper.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egyY5k1OTSkL",
        "outputId": "25483079-6499-4c23-8d7c-1eaf1172ba71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviewing /content/Object_Distance_Estimation_from_a_Single_Moving_Camera_for_Advanced_Driver_Assistance_System.pdf\n",
            "Extracting text from PDF...\n",
            "Splitting into sections...\n",
            "Loading summarization model (facebook/bart-large-cnn)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading text generation model (google/flan-t5-base)...\n",
            "Loading sentence-transformers embedder (all-MiniLM-L6-v2)...\n",
            "Summarizing the full paper (may take a while)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Summarizing chunks: 100%|██████████| 8/8 [03:54<00:00, 29.35s/it]\n",
            "Summarizing chunks: 100%|██████████| 2/2 [00:37<00:00, 18.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating structured review text...\n",
            "\n",
            "=== SHORT SUMMARY ===\n",
            "\n",
            "Distance estimation is a crucial component of advanced driver assistance systems (ADAS) Researchers felt the need for multi-object detection in real-time using morepragmatic vision-based (monocular, stereo cameras) You Only Look Once (YOLO) is one of the state-of-the-art works.\n",
            "\n",
            "=== STRUCTURED REVIEW ===\n",
            "\n",
            "STRENGTHS, WEAKNESSES, NOVELTY_ASSESSMENT, CLARITY, METHODOLOGY_ISSUES, SUGGESTIONS, RECOMMENDATIONs\n",
            "\n",
            "=== NOVELTY HEURISTIC ===\n",
            "\n",
            "Novelty score (0 low - 1 high): 0.500\n",
            "\n",
            "=== UNCLEAR SENTENCES (examples) ===\n",
            "\n",
            "-  7: Residual plot Further, to check the model sensitivity at different posi- tions of the objects, a comparison of the output of the three TABLE I: Performance of the machine learning models for depth correction Model RMSE R2 Linear regression 12.906 0.947 Decision tree regression 15.526 0.936 Random\n",
            "-  Object Distance Estimation from a Single Moving Camera for Advanced Driver Assistance System Anurag Thombre∗†, Avinash Kumar Rai‡, Lalit Dumka§, and Amit Agarwal∗ ∗Department of Civil Engineering, Indian Institute of Technology Roorkee, Haridwar, India ‡ Department of Electronics and Communications,\n",
            "-  Acceptable evaluation metrics, such as Residuals, Absolute Relative difference (AbsRel), Squared Relative difference (SqRel), RMSE (linear), RMSE log, and Mean Absolute Error (MAE) are employed for performance evaluation [13] and defined as follows: ei = yi −ˆyi (5) MAE = 1 n n X i=1 |ei| (6) Abs Re\n",
            "-  The present study is carried out to address the above- mentioned challenges and expand the knowledge base in this domain; the specific contributions of this work are: (i) estimate the object distances utilizing a single moving camera mounted on a vehicle by employing camera optics- based and deep le\n",
            "-  Sq Rel = 1 n N X i=1 \u0012e2 i yi \u0013 (8) RMSE = v u u t 1 n n X i=1 (ei)2 (9) RMSE log = v u u t 1 N N X i=1 (log yi −log ˆyi)2 (10) where, yi is observation from field (ground truth) and ˆyi is from the model.\n",
            "-  This would result in the sensor height and width as follows: ws [mm] = ax hs [mm] = bx x [mm] = ss [mm] √ a2 + b2 Further, assuming that the sensor is placed at a distance of focal length, the focal length (f [mm]) of the camera is computed using the Equation (3).\n",
            "\n",
            "=== CANDIDATE LINES (copy/paste) ===\n",
            "\n",
            "- STRENGTHS, WEAKNESSES, NOVELTY_ASSESSMENT, CLARITY, METHODOLOGY_ISSUES, SUGGESTIONS, RECOMMENDATIONs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9b0B9DW_u2iL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}